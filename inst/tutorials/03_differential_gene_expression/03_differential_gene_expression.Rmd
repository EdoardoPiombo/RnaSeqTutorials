---
title: "Differential Gene Expression (DGE)"
author: "Nicolas Delhomme and Edoardo Piombo"
tutorial:
  id: "org.bnbio.tutorials.03_differential_gene_expression"
  version: 0.6
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---



```{r setup, include=FALSE}
# to run locally replace tutorials/03_differential_gene_expression/www with inst/tutorials/03_differential_gene_expression/www

# to run as an app replace tutorials/03_differential_gene_expression/www with www

# libs
suppressPackageStartupMessages({
  library(DESeq2)
  library(here)
  library(learnr)
  library(MASS)
  library(tidyverse)
  library(vsn)
  library(LSD)
})
  
# options
knitr::opts_chunk$set(echo = FALSE)
tutorial_options(
  exercise.reveal_solution=TRUE,
  exercise.lines=10)

#helper functions
source(here("inst/tutorials/02_exploratory_data_analysis/www/featureSelection.R"))
source(here("inst/tutorials/03_differential_gene_expression/www/volcanoPlot.R"))
source(here("inst/tutorials/03_differential_gene_expression/www/gopher.R"))


# step to reproduce
# ---
# data
# txi <- readRDS(here("tutorials/03_differential_gene_expression/www/tximport.rds"))
# counts <- round(txi$counts)
# sample_file <- here("tutorials/03_differential_gene_expression/www/samples_table.tsv")
# samples <- read_tsv(sample_file,col_types=c("cfff"))
# dds <- DESeqDataSetFromTximport(
#   txi=txi,
#   colData = samples,
#   design = ~ time * treatment)
# saveRDS(dds,file=here("tutorials/03_differential_gene_expression/www/dds-pre.rds"))
# dds <- DESeq(dds)
# saveRDS(dds,file=here("tutorials/03_differential_gene_expression/www/dds-post.rds"))
# G03_vs_G02_at_T03 <- results(dds,name="treatment_G03_vs_G02")
# saveRDS(G03_vs_G02_at_T03,file=here("tutorials/03_differential_gene_expression/www/G03_vs_G02_at_T03.rds"))
# G03_vs_G02_at_T04 <- results(dds,list(c("treatment_G03_vs_G02","timeT04.treatmentG03")))
# saveRDS(G03_vs_G02_at_T04,file=here("tutorials/03_differential_gene_expression/www/G03_vs_G02_at_T04.rds"))
# dds_T04 <- dds[,dds$time=="T04"]
# design(dds_T04) <- ~ treatment
# dds_T04 <- DESeq(dds_T04)
# saveRDS(dds_T04,file=here("tutorials/03_differential_gene_expression/www/dds_T04-post.rds"))
# G03_vs_G02_at_T04_simple <- results(dds_T04)
# saveRDS(G03_vs_G02_at_T04_simple,file=here("tutorials/03_differential_gene_expression/www/G03_vs_G02_at_T04_simple.rds"))
```

## Introduction

In the previous tutorial, we saw that the data quality looks good, and we saw that the samples all belong to one of two conditions. Today, we will learn how to determine which genes are upregulated or downregulated in one of the two conditions, compared to the other.


Before we get there though, we need to learn a bit more about the processes that `DESeq2`, the package we will use for DGE is doing. 

```{r intro-quizz}
quiz(caption="RNA-Seq data normalisation",
      question("We have seen previously that RNA-Seq data needs to be normalised for:",
               answer("the difference in sequencing depth",correct=TRUE),
               answer("the data heteroscedasticity",correct=TRUE),
               answer("the total size of the transcriptome in bp"),
               answer("differently for single-end (SE) and paired-end (PE) sequencing")))
```

Furthermore, we have seen that correcting for the library size differences introduced the most important assumption about DGE, namely that we assume that **"most genes are not differentially expressed"**. 

<!-- Edoardo: maybe this part is a little too statistical for them? I agree that we need to explain why it is necessary to adjust the pvalue, but maybe we can do it later and in simpler terms?

We have also seen that RNA-Seq data is best explained by a _negative binomial distribution_ with

$$\vartheta^{2} = \mu + \theta\mu^{2}$$

where $\theta$ is the dispersion and $\mu$ the mean. It can be noted that $\mu$ models the technical noise of the data while $\sqrt{\theta}$ represents its "biological coefficient of variation".

These are the properties of the data we have already seen, but the design of most biological studies brings in a couple additional challenges. Indeed, the data we work with has very different dimensions; it is typically the observation of many genes across few samples - and this results in the following limitations:

-->

RNAseq datasets have two characteristics that make it hard to extract meaningful conclusions from them, and both of them need to be dealt with during the analysis:
1. few samples makes it hard to estimate parameters (such as _e.g._ the BCV $\sqrt{\theta}$)
2. many genes means we are running many tests



## `DESeq()`

Let's start by running `DESeq()`! Figure out how to (you need to specify the pathway to the rda file you saved yesterday to load the dds object).
Then, save the after-run dds object as a rds file

```{r deseq, exercise=TRUE, exercise.eval=TRUE,exercise.timelimit=300}
dds <- readRDS(here("inst/tutorials/02_exploratory_data_analysis/dds.rds"))
dds
saveRDS(dds,file=here("inst/tutorials/03_differential_gene_expression/www/dds-post.rds"))
```

```{r deseq-hint}
?DESeq
```

```{r deseq-solution}
dds <- readRDS(here("inst/tutorials/02_exploratory_data_analysis/dds.rds"))

dds <- DESeq(dds)
#Now let's save the results
saveRDS(dds,file=here("inst/tutorials/03_differential_gene_expression/dds-post.rds"))
```

And that's it! In a single command, we have run the DGE! In a way, `DESeq()` is a black box. This is in my opinion, the biggest difference with the other, equally well performing, DE package `edgeR` (see [Schurch _et al._, RNA, 2016](https://doi.org/10.1261%2Frna.053959.115) for a comparison of DE tools). `DESeq2` hides the complexity away from the end-user, making automated educated decision based on the properties of the data, while `edgeR` leave all decisions to the end-user who needs to combine the different steps of the DE analysis on its own. Nonetheless, the `DESeq()` steps can be decomposed as we have seen last week with _e.g._ the `estimateSizeFactors()` step we ran, but `edgeR` remains the most versatile of the two (_caveat:_ provided you know what you are doing).

Last but not least, `DESeq()` is unlike a true black box, exposing all the steps it performs

```{r deseq-quizz}
quiz(caption="`DESeq()` steps",
      question("Out of the six steps mentioned by `DESeq()`, which ones address the difference in sequencing depth and data heteroscedasticity?",
               answer("the first and second"),
               answer("the first only"),
               answer("all but the sixth",correct=TRUE),
               answer("all")))
```

### Unbalanced data dimensions

<!-- 
Here I prepare a post-run dds object that they will use later
-->

```{r dds-post, eval=TRUE, include=FALSE}
dds <- readRDS(here("inst/tutorials/03_differential_gene_expression/dds-post.rds"))

```

The first and second steps are about calculating the normalisation factor (for the sequencing depth) and the dispersion (of the negative binomial distribution), respectively. The third to fifth are actually addressing the first common issue of biological studies design we mentioned earlier.

Let us visualise the problem. Imagine a gene which true average expression is `3` in an infinitely sized population. We perform a studies in which we sample 3 individuals from that population (_i.e._ three biological replicates). We can simulate the results, assuming the expression of the gene to be normally distributed in the population, centered on 3 as follows: `rnorm(n=3,mean=3)`. For the sake of the argument, imagine we could redo that experiment a thousand times and compare the resulting average distribution we obtain to the "truth". Run the code below to see the results.

```{r params, exercise=TRUE, exercise.eval=TRUE}
ggplot(tibble(x=sapply(1:1000,function(i){mean(rnorm(3,mean=3))}))) +
  geom_histogram(aes(x=x)) + geom_vline(xintercept=3,color="red",linetype="dashed") +
  xlim(0,6) + labs(x="measured expression")
```

Using the block above, simulate what would happen if you were to increase the sampling size.

```{r params-quiz}
quiz(caption="The more samples...the merrier",
     question("When did you observe a visual difference?",
              answer("4"),
              answer("6"),
              answer("12",correct=TRUE),
              post_message="There is a no exact answer, but Schurch _et al._ highlighted the number 12 in their publication."))
```

Now that we have visualised the limitation of having few samples, let me remind you of the assumption we already made: that **"most genes are not DE"**. Could we use this at our advantage here? The answer is *YES*. Based on that assumption, we can further assume that most genes are drawn from the same population with the same characteristics.

<!--Edoardo: I rephrased this block a little
In other words, we have done many sampling as in the naÃ¯ve examples above. So, if we model the dispersion distribution (it will be heteroscedastic), we can then **shrink** the dispersion values we calculated towards the center value defined by the model. With that information, use the `plotDispEsts()` function to visualise and interpret that process.
-->

In other words, we can use the data expression value of similarly expressed genes to shrink the dispersion values of those genes. Basicly, we use the expression values of similarly expressed genes as if they were additional samplings of the gene whose dispersion values we are currently shrinking. So, if we model the dispersion distribution (it will be heteroscedastic), we can then **shrink** the dispersion values we calculated towards the center value defined by the model. With that information, use the `plotDispEsts()` function to visualise and interpret that process.


```{r disp, exercise=TRUE, exercise.eval=TRUE, exercise.setup= "dds-post"}

```

```{r disp-hint}
?`plotDispEsts,DESeqDataSet-method`
```

```{r disp-solution}

plotDispEsts(dds)
```

The black dots are the initial dispersion values, the red line is the variance-mean relationship model and the blue dots are the shrunk dispersion estimates.

```{r disp-quiz}
quiz(caption="Have you noticed?",
     question("What are the blue circles in the top of the plot?",
              answer("genes which could not be shrunk",correct=TRUE),
              answer("genes without expression"),
              answer("genes used as a training set for the model"),
              answer("genes used as a testing set for the model"),
              post_message="When the dispersion value of a gene is too high, DESEQ2 assumes that the gene behaves differently from similarly expressed ones, and leaves it as it is."))
```

### Multiple testing

Once `DESeq()` has estimated all the parameters it needs, it will apply its model to test for differential expression according to the `design` we provided. We will next look at models before looking into the results of the DGE, but for now we will have a look at the last challenge of RNA-Seq data analysis, namely the fact that we have high dimensionality in our data: we have many genes, so we will perform as many tests.

---

#### p-values

Every test will return a test score associated with a significance value; a p-value. Do you recall statistics 101?

**The p-value is the probability of obtaining a test statistic at least as extreme as the one observed, if the null hypothesis is true** ( _i.e._ if there is not true signal in the data).

```{r p-value-quiz}
quiz(caption="Probabilities",
     question("In the absence of real signal, what is the p-value of getting a test statistic having a 5% probability?",
              answer("0.025 if the test is two-sided"),
              answer("5%",correct=TRUE),
              answer("95%"),
              answer("0.975 if the test is two-sided")),
     question("In the absence of signal, in a study with 10,000 genes, how many p-value equal to or smaller than 5% would we get?",
              answer("none!"),
              answer("500",correct=TRUE),
              answer("it will vary from studies to studies"),
              answer("250 if the test is two-sided")))
```

--- 

No comments...

![https://xkcd.com/882/](images/significant.png){width=80%}

---

#### False Discovery Rate

**We clearly need to change perspective!** Instead of limiting the false positive probability for each _individual_ test, we can instead limit:

1. the probability of obtaining any false positive (Family Wise Error Rate - FWER)
2. the fraction of false positives among significant genes (False Discovery Rate - FDR)

`DESeq()` performs the latter, applying a [Benjamini-Hochberg](https://en.wikipedia.org/wiki/False_discovery_rate#Benjamini%E2%80%93Hochberg_procedure) [multiple testing correction](https://en.wikipedia.org/wiki/Multiple_comparisons_problem). The resulting FDR is a measure for a set of genes. In a set of genes with FDR of 5%, about 5% will be false discoveries. However, we do not know which ones! It might as well be the most significant ones!

_q-values_ also known as _adjusted p-values_ (padj in `DESeq()` results) are gene-wise significance measures adjusted to reduce the number of significant genes according to the desired FDR threshold.

In other words, if we set any gene with padj < 0.05 as significant, then 5% of the significant genes will be due to random effects, which means that the significant gene set has an FDR or 5%. However, if we set any gene with non adjusted pvalue < 0.05 as significant, then 5% of all genes in the genome will be determined to be significant because of random effects.
In a situation in which we have 10,000 genes, 300 of which are differentially expressed, the pvalue adjustment reduces the number of genes erroneously reported as significant from 500 (10,000 * 0.05) to 15 (300 * 0.05)!


The FDR is the less strict technique of pvalue adjustement. A number of other techniques are available and can be employed by DESeq2, if the proper options are set.

---

#### Independent filtering

A last caveat. Multiple testing corrections will be affected by the number of tests that have been conducted. That means that the higher is the number of genes that you test for differential expression, the most stringent the pvalue adjustment will have to be. Note that the pvalue adjustement does not "know" which genes are differentially expressed for real, and which ones are due to random effects, so it can occasionally happen that genuinely differentially expressed genes result as non-significant, expecially if the are lowly upregulated or downregulated.

Keeping this in mind, try to answer the following question.

```{r indpt-filter-quizz}
quiz(caption="Ideal number of tests",
     question("Which gene set should be selected for multiple testing correction?",
              answer("all genes"),
              answer("expressed genes"),
              answer("gene expressed at a level higher than the noise",correct=TRUE),
              answer("differentially expressed genes"),
              post_message="`DESeq2` does is automatically, while it is a manual step in `edgeR`"))
```

As mentioned earlier, `DESeq()` does a lot for us, including adjusting the multiple testing correction by selecting genes, whose expression is deemed informative using a method called [independent filtering](http://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#independent-filtering-of-results).

The independent filtering results are stored as part of the DE results object in its `metadata` slot. Use the code block below to run the `results()` function on your `dds` object, then lookup its metadata (**Hint**: S4 conventions have it so that a slot accessible to the user would have an accessor function named after the slot).

```{r indpt-filter, exercise=TRUE, exercise.eval=FALSE, exercise.setup="dds-post"}

```

```{r indpt-filter-hint}
?results
?metadata
```

```{r indpt-filter-solution}
metadata(results(dds))
```

From that output, we can observe that the independent testing has one parameter called `theta` $\theta$ and that $\theta$ represents the quantile of the expression values ranked in ascending order. `DESeq()` decides on a threshold to remove genes that are uninformative (their noise is too large for their signal to ever be significantly different) using a `lowess` ( LOcally WEighted Scatterplot Smoothing, a type of locally-weighted polynomial regression) regression. The results from the regression are available in the `lo.fit` entry of the `metadata(res)` list. We could visualise that regression in a ggplot visualisation.

```{r indpt-filter-view, exercise=TRUE, exercise.eval=FALSE, exercise.setup="dds-post"}
mData <- metadata(results(dds))


```

```{r indpt-filter-view-hint-1}
tibble(x=mData$lo.fit$x,
       y=mData$lo.fit$y)
?geom_point
?geom_line
?labs
```

```{r indpt-filter-view-hint-2}
ggplot(tibble(x=mData$lo.fit$x,
       y=mData$lo.fit$y),
       aes(x=x,y=y)) +
  geom_point() +
  geom_line() +
  labs(x="percentile of expression",y="number of rejections")

# you could consider adding a vertical line at the cutoff selected by DESeq()
?geom_vline
mData$filterTheta

```

```{r indpt-filter-view-solution}
mData <- metadata(results(dds))
ggplot(tibble(x=mData$lo.fit$x,
              y=mData$lo.fit$y),
       aes(x=x,y=y)) +
  geom_point() +
  geom_line() +
  labs(x="percentile of expression",y="number of rejections") +
  geom_vline(xintercept=mData$filterTheta,col="red",linetype="dashed")
```

As you can observe, `DESeq()` selects a cutoff that falls short of the maxima of the regression, where the number of rejections is maximised. On the left side of that point, the number of rejections increases, meaning we are actually removing noise. To the right, the number of rejections decreases again, meaning we are actually removing informative genes and loosing power. `DESeq()` selects a value prior to the maxima to ensure no genes located around the signal-to-noise ratio get wrongly removed. Better to have a slightly stricter multiple testing correction than losing putative candidates.

```{r indpt-filter-view-quizz}
quiz(caption="Where is the rest of the data?",
     question("Have you noticed that the quantile of expression does not start at 0%? Why?",
              answer("Non expressed genes are by default uninformative",correct=TRUE),
              answer("Only half of the data is used for testing, the rest was used for training."),
              answer("There was no rejection prior to that point.")
     ))
```

**We've made it!** We have finally looked at all the statistical steps that `DESeq()` (and `edgeR`) use to perform a sound Differential Expression Analysis. Remember that the strongest caveat stem from the assumption we had to accept, that **most genes are NOT differentially expressed**. 

Last, we have seen how to retrieve the results of the differential expression, and these would look as follows:

```{r results, echo=FALSE, eval=TRUE}
dds <- readRDS(here("inst/tutorials/03_differential_gene_expression/dds-post.rds"))
head(results(dds))

```

Note that soome genes have only missing values (they were never expressed), while others have a missing `padj`. This is the telltale sign that those genes were deemed uninformative.

We will revisit these results, but prior to that we need to learn about modelling in R, as the results we just observed were tests conducted on the model $expression = f(Condition)$.


<!-- Edoardo:
I am not sure that all the Models section is necessary for them.
-->

## Models

Models are an inherent part of the `R` language, and they are arguably hard to grasp - my opinion - unless you are a statistician. Luckily there are many resources that can help us navigate and understand these:

1. [The design matrix vignette from the RNAseq123 package](https://bioconductor.org/packages/release/workflows/vignettes/RNAseq123/inst/doc/designmatrices.html)
2. [Charlotte Soneson's ExploreModelMatrix package](https://bioconductor.org/packages/release/bioc/html/ExploreModelMatrix.html)
3. [Hadley Wickam's R 4 Data Science book, chapters 22 to 25](https://r4ds.had.co.nz/model-intro.html)

Points 1. and 2. have a focus on RNA-Seq data analysis, while 3. is more generic (and also gets much more advanced). The latter is a great intro into `R` modelling if you need to do that. 

Instead of going through any of these (we will use Charlotte's tools a little bit later on), I would rather like to demonstrate the use of models on a toy example.

### Animals' brain _vs._ body weight.

The library `MASS` ( _M_ odern _A_ pplied _S_ tatistics with _S_ ) has a dataset called `Animals` about animals' brain and body weight. In the following, we will model the relationship between the two. An initial hypothesis we can formulate is that there is a linear relationship between the two. Use ggplot to visualise the animals brain and body weight.

```{r model, exercise=TRUE, exercise.eval=TRUE}
library(MASS)
head(Animals,5)
```

```{r model-hint-1}
ggplot(Animals,aes(...)) + 
  geom_point()

# you could try to add a visualisation of a linear model

?geom_smooth

# the arguments method and se might be useful
```

```{r model-hint-2}
ggplot(Animals,aes(...)) + 
  geom_point() + 
  geom_smooth(method=...,se=...)
```

```{r model-solution}
ggplot(Animals,aes(x=body,y=brain)) + 
  geom_point() + 
  geom_smooth(method=lm,se=FALSE)
```

Clearly, this does not look like a great fit. Nonetheless, we can model that data using a linear model (`lm()`) using the following `formula`: `brain ~ body`; _i.e._ $brain = f(body)$ and then look at its fit. For that we can look at the $\sum{residuals^{2}}$ as well as its $R^{2}$ value. You can use the `deviance()` and `summary()` functions to look at these respectively

```{r lm, exercise=TRUE, exercise.eval=TRUE}
# We fit a linear model (lm)
# then get the sum of squared residuals
# then we do the same but as a function
# and finally get the R2 value

fit <- lm(data=Animals,brain ~ body)
```

```{r lm-hint}
?sum
?resid
?`^`
?deviance
?summary
```

```{r lm-solution}
fit <- lm(data=Animals,brain ~ body)
# the sum of squared residuals
sum(resid(fit)^2)
# same as a function
deviance(fit)
# the R^2
summary(fit)$r.squared
```



Without a comparison, it is hard to know whether the $\sum{residuals^{2}}$ is a good value or not, but as we know the smaller, the better, we seem pretty off here. And the 
$R^{2}$, which goes from 0 to 1 (a perfect fit), is also clearly underwhelming. 

Might have something gone wrong with our expectations? Possibly. On a linear scale, errors are multiplicative, while they become additive on a logarithmic scale. Use the next block to reproduce the fit above but using the logarithm of the `body` and `brain` weights (the base of the logarithm, natural, 2, 10, ... does not matter).

```{r model-log, exercise=TRUE, exercise.eval=TRUE}

```

```{r model-log-hint}
ggplot(Animals,aes(x=log10(body),y=log10(brain))) + ...

fit <- lm(data=Animals,log10(brain) ~ log10(body))

...

```

```{r model-log-solution}
fit <- lm(data=Animals,log10(brain) ~ poly(log10(body),2))

ggplot(Animals,aes(x=log10(body),y=log10(brain))) + 
  geom_point() + 
  geom_smooth(method=lm,se=FALSE)

fit <- lm(data=Animals,log10(brain) ~ log10(body))

deviance(fit)

summary(fit)$r.squared

```

This is more like it. The $\sum{residuals^{2}}$ is much smaller than previously and the $R^{2}$ (approx. the percent of variance captured by the model) is higher.
 
```{r model-log-quiz}
quiz(caption="Good enough?",
     question("Are you satisfied by that result?",
              answer("Yes"),
              answer("No, the fit could be better",correct=TRUE)))

```

The simple linear model we used $y=ax+b$ seem to be above most values for low body weight and above for high body weight. We could try a polynomial (_poly()_) model (or a more robust natural spline _ns()_) Extend the following code to visualise the $\sum{residuals^{2}}$ and $R^{2}$. Plot the new model


```{r poly, exercise=TRUE, exercise.eval=TRUE, exercise.lines=10}
fit <- lm(data=Animals,log10(brain) ~ poly(log10(body),2))
```

```{r poly-solution}
deviance(fit)

summary(fit)$r.squared

ggplot(Animals,aes(x=log10(body),y=log10(brain))) + 
  geom_point() + 
  geom_smooth(method=lm,se=FALSE,formula=y ~ poly(x,2))

```

Not too bad, but still:

1. The variance seem to increase with the body weight. This is an issue as it means the residuals are not independent, whereas they should be normally distributed
2. Three dots fill odd, don't they? Large bodied animals with comparatively small brain? 

Let's take a closer look:

```{r residuals, exercise=TRUE, exercise.eval=TRUE, exercise.setup="poly"}
plot(fit$fitted.values,fit$residuals)
```

Definitely something off with the variance, let's look at these three extreme values

```{r dinosaurs, exercise=TRUE, exercise.eval=TRUE}

ggplot(Animals %>% mutate(color=ifelse(body>9000 & brain < 1000,"red","blue")),
       aes(x=log10(body),y=log10(brain))) + 
  geom_point(aes(col=color)) + 
  geom_smooth(method=lm,se=FALSE,formula=y ~ poly(x,2))
```

What are these?

```{r, echo=TRUE, eval=TRUE}
Animals %>% filter(body>9000 & brain < 1000)
```

Oh well... **dinosaurs** :-D

Redo the simple linear model, filtering for animals with a body weight greater than 9000 and a brain weight lesser than 1000. Use the `dplyr` `filter()` function.

```{r final-model, exercise=TRUE, exercise.eval=TRUE}

```

```{r final-model-hint-1}

# filtering using a boolean vector
?filter

# how to negate a boolean vector
?`!`

```

```{r final-model-hint-2}
ggplot(Animals %>% filter(!( ... )),
aes(x=log10(body),y=log10(brain))) + 
  geom_point() + 
  geom_smooth(method=lm,se=FALSE)

fit <- lm(data=Animals %>% filter(!(...)),log10(brain) ~ log10(body))

deviance(fit)

summary(fit)$r.squared

plot(fit$fitted.values,fit$residuals)

```

```{r final-model-solution}
ggplot(Animals %>% filter(!(body>9000 & brain < 1000)),
aes(x=log10(body),y=log10(brain))) + 
  geom_point() + 
  geom_smooth(method=lm,se=FALSE)

fit <- lm(data=Animals %>% filter(!(body>9000 & brain < 1000)),
log10(brain) ~ log10(body))

deviance(fit)

summary(fit)$r.squared

plot(fit$fitted.values,fit$residuals)

```

Wow! A really great $R^{2}$, a low $\sum{residuals^{2}}$ and residuals that seem (more or less) independent to either variables of the model.

**Note:** "base" `R` provide some excellent assessment plots, try: `plot(lm(data=Animals %>% filter(!(body>9000 & brain < 1000)),log10(brain) ~ log10(body)))`

Now, we could start to explore the data and look for points that deviates from the model.

```{r diff, exercise=TRUE, exercise.eval=TRUE }
ggplot(Animals %>% filter(!(body>9000 & brain < 1000)) %>% 
         rownames_to_column("species"),
aes(x=log10(body),y=log10(brain))) + 
  geom_point() + xlim(c(1,2)) +
  geom_text(aes(label=species),nudge_y=0.1) +
  geom_smooth(method=lm,se=FALSE)
```

It would appear `Chimpanzee` and `Human` have differentially larger brain that their body size would let us predict!

---

### Summary

Why was that relevant? Imagine: $brain=gene\_expression$ and $body=Condition$. Running `DESeq()` on our data will have done something highly similar to what we just did and `Chimpanzee` and `Human` would be our "candidate" differentially expressed genes!

## Results

Going back to our studies, the model we provided to `DESeq()` is $\tilde{ }Condition$. `DESeq()` performed a DE analysis, conducted tests and applied a multiple testing correction as we have seen. But what did he perform the comparison on? Figure it out using the `resultsNames()` and `results()` function.

```{r results-names, exercise=TRUE, exercise.eval=TRUE, exercise.setup="dds-post"}

```

```{r results-names-hint}
?resultsNames()
?results()
```

```{r results-names-solution}
resultsNames(dds)
results(dds)
```

`R` has by default calculated one contrasts and has returned its result, from the call to `results()`. If you have had more than two values in the Condition column of your metadata, more contrasts would have been calculated, and the result of the last one would have been returned by default.

Contrasts are (to me at least) headache generators, but the vignettes of the `DESeq2` and `edgeR` packages are really useful to understand them. Moreover, I also always cross-validate my results, by looking at heatmaps and validating the log ratio by taking a few example genes and doing the maths (or at least checking manually that one group of samples has many more reads mapping to those genes).


Now that we know about contrasts, we will learn to extract them accordingly.

---

#### Baseline

Use the following code block to find what the baseline is (remember that `R` sorts factors alphabetically).

```{r baseline, exercise=TRUE, exercise.eval=TRUE, exercise.setup="dds-post"}

```

```{r baseline-hint}
?resultsNames
dds$Condition
```

```{r baseline-solution}
resultsNames(dds)
levels(dds$Condition)
```

**Note:** If the default ordering is not what you want, and you have several contrasts, you can use _e.g._ `dds$Condition <- relevel(dds$Condition,"A_New_Condition")` to make `A_New_Condition` the reference.

---

#### Choosing contrasts

If you have more contrasts, the default one is always the last one returned by the function resultsNames()

```{r default-contrast, exercise=TRUE, exercise.eval=TRUE, exercise.setup="dds-post"}
resultsNames(dds)
```



To select a different contrast, we can use the `name=` argument to the `results()` function call.
You have only one contrast in this tutorial, but try to specify it explicitly in the results() function, as you would do if you were selecting one contrast among several.

```{r contrast, exercise=TRUE, exercise.eval=TRUE, exercise.setup="dds-post"}

```

```{r contrast-hint}
results(dds,name=...)
```

```{r contrast-solution}
resultsNames(dds)
some_results <- results(dds,name="A_CONTRAST_YOU_CHOOSE")
```




Now, wait! How do we know how many genes are differentially expressed? Good question, give a try at `summary()`.

```{r summary, exercise=TRUE, exercise.eval=FALSE, exercise.setup="dds-post"}
resultsNames(dds)
some_results <- results(dds,name="A_CONTRAST_YOU_CHOOSE")

```

```{r summary-hint}
summary(...)
```

```{r summary-solution}
resultsNames(dds)
some_results <- results(dds,name="A_CONTRAST_YOU_CHOOSE")

summary(some_results)
```

Wait again! How do we know what cutoff(s) to use? Good question, look at [Table 2](https://rnajournal.cshlp.org/content/22/6/839/T2.expansion.html) from Schurch _et al._, RNA, 2016. With less than 6 replicates per condition, the FDR is controlled for log2 fold-changes $>=0.5$. Try to find out how this out.

```{r cutoffs, exercise=TRUE, exercise.eval=FALSE, exercise.setup="dds-post"}
resultsNames(dds)
#Select the condition you prefer instead of the one I wrote here
some_results <- results(dds,name="Condition_6h_5C_vs_24h_neg5C")
some_results %>% 

```


```{r cutoffs-hint}
?is.na
?filter
?abs
?nrow

```


```{r cutoffs-solution}
some_results %>%
  filter(!is.na(padj)) %>% 
  filter(padj <= 0.01) %>%
  filter(abs(log2FoldChange) >= 0.5) %>%
  nrow()
```


<!-- Edoardo: I commented out the next section as they should not have more than one contrast

#### Other contrasts

What if we are interested in comparing treatment and control at T04 (the reference being control at T03)? What about the time effect specifically in the induced samples (the reference being in between the mock samples)? None of the existing contrasts can give us that information. Here, we will need to use the `contrast=` argument of the `results()` function and that is where the previous section will become handy, as well as Charlotte's `ExploreModelMatrix` - [link to the app](http://terra.upsc.se/ExploreModelMatrix).

`contrast=` can take three possible type of arguments (from the `?results()` help page):

* a character vector with exactly three elements: the name of a factor in the design formula, the name of the numerator level for the fold change, and the name of the denominator level for the fold change (simplest case)
* a list of 2 character vectors: the names of the fold changes for the numerator, and the names of the fold changes for the denominator. these names should be elements of resultsNames(object). if the list is length 1, a second element is added which is the empty character vector, character(). (more general case, can be to combine interaction terms and main effects)
* a numeric contrast vector with one element for each element in resultsNames(object) (most general case)

----

```{r G03_vs_G02_at_T04-quiz}
quiz(caption="Looking for G03 _vs._ G02 at T04",
     question("Which contrast can we use for that?",
              answer('c("treatment","G03","G02")'),
              answer('list(c("treatment_G03_vs_G02","timeT04.treatmentG03"))',correct=TRUE),
              answer("c(0,0,1,1)",correct=TRUE)))
```

Question: Take a minute to reflect on how that is different from `timeT04.treatmentG03` 

Answer: (T04 at G03 of expression the to contribution specific the, term interaction an is timeT04.treatmentG03 that is answer the) <-- read the answer from right to left.

As you can see, there are multiple ways to write contrasts, which is why it is important (IMO) to visualise the results and assess whether we got the contrasts right.

-->


#### Assessment plots
What? You thought you were done with quality plots after the day of yesterday?
*Think again!* You are *never* done with quality plots.

##### Volcano plot

One of the first (and most important) assessment plots to do is a so-called volcano plot.

```{r volcano-plot, exercise=TRUE, exercise.eval=TRUE, exercise.setup = "dds-post"}
resultsNames(dds)
#Select the condition you prefer instead of the one I wrote here
some_results <- results(dds,name="Condition_6h_5C_vs_24h_neg5C")
volcanoPlot(some_results)
```


Something essential there is to assess whether **most genes are not differentially expressed**, our most essential assumption. The volcano plot presented here uses a color code to represent as a third dimension, the density of the genes at given coordinates. If you ignore the blue dots circled in cyan, you can see at the bottom that the color ranges from grey (very sparse) to blue (sparse) to red (dense) to yellow (very dense). Here the highest density is ay $(0,0)$ hence, most genes are not DE :-).

Note that volcanoPlot() is a function we wrote. To see  exactly what it does and how it does it, check out the original code at the pathway "/mnt/picea/projects/functional-genomics-course/spring2024/data/week2/UPSCb-common/src/R/volcanoPlot.R"

##### Heatmap

In the Biological QA, we have used the `gplots` package `heatmap.2` function. That function follows the principles of base `R` and while being performant, is not as easily customisable as implementations that are inspired from the `tidyverse`. Here we will use the `ComplexHeatmap` package `Heatmap()` and `HeatmapAnnotation()` functions to visualise the expression of the DE genes in the contrast we just ran. This is also a good sanity check as we should obtain a very blue and red chequered heat-map.

<!-- Edoardo: I tried to rewrite the code below using tidyverse when possible -->
```{r heatmap, exercise=TRUE, exercise.eval=TRUE, exercise.setup= "volcano-plot"}
suppressPackageStartupMessages(library(ComplexHeatmap))


row_sel <-some_results %>%
  as.data.frame() %>%
  filter(!is.na(padj)) %>% 
  filter(padj <= 0.01) %>%
  filter(abs(log2FoldChange) >= 0.5) %>%
  rownames()


col_sel <- dds$Condition

vsd <- varianceStabilizingTransformation(dds,blind=FALSE)
vst <- assay(vsd)
vst <- vst - min(vst)

Heatmap(t(scale(t(vst[row_sel,1:ncol(dds)]))),
        clustering_distance_columns="pearson",
        clustering_method_columns="ward.D2",
        clustering_distance_rows="pearson",
        clustering_method_rows="ward.D2",
        show_row_dend=FALSE,
        show_row_names=FALSE)
```

A point of caution. Some low (or very low) expressed genes can be called differentially expressed. Hence it is good pratice to plot the distribution of the average counts of the DE genes. Use the code block below to take a look (suggestion: `ggplot()`, `geom_boxplot()`, as well as `scale_y_log10()` as the counts are linear...)

```{r counts, exercise=TRUE, exercise.eval=TRUE, exercise.setup= "volcano-plot"}


row_sel <-some_results %>%
  as.data.frame() %>%
  filter(!is.na(padj)) %>% 
  filter(padj <= 0.01) %>%
  filter(abs(log2FoldChange) >= 0.5) 

```

```{r counts-hint-1}
ggplot(DATA,AES) + geom_boxplot() + scale_y_log10()
```

```{r counts-hint-2}
ggplot(tibble(y=...$baseMean),aes(y=y)) + geom_boxplot() + scale_y_log10()
# you could improve this by setting the y axis label
# you could also provide an `x` variable to replace the x axis continuous scale
```

```{r counts-hint-3}
ggplot(tibble(y=...$baseMean),aes(y=y,x="Condition")) + geom_boxplot() + scale_y_log10("average normalised counts")
# you could add another violin layer, give the boxplot a `notch`, and remove the x axis `x` label
```


```{r counts-solution}

row_sel <-some_results %>%
  as.data.frame() %>%
  filter(!is.na(padj)) %>% 
  filter(padj <= 0.01) %>%
  filter(abs(log2FoldChange) >= 0.5) %>% 
  rownames()


ggplot(tibble(y=some_results[row_sel,"baseMean"]),aes(y=y,x="Condition")) + 
  geom_violin() + scale_y_log10("average normalised counts") + 
  scale_x_discrete(element_blank()) + geom_boxplot(notch=TRUE)
```

The vast majority of DE genes should be "expressed" with at least at 50-100 counts.


<!-- Edoardo: I commented out the next section, as since they will have a single variable with only two factors, they should not have the need for Venn diagrams.

### Comparison

As you recall, we saw in the EDA that time point `T03` might be too early to see a treatment effect. What would be the difference with the results we obtained if we were to ignore the samples from `T03` altogether and have a simpler `~treatment` model?

For that we need to subset the dds object and adjust the design. Subsetting can be done using the `[` pragma, with rows as genes and samples as columns, _i.e._ `[genes,samples]`. In our case, we would only want the `T04` samples. To adjust the design you can use `design() <-`. Give it a try.

```{r subset, exercise=TRUE, exercise.eval=TRUE, exercise.setup="dds-post"}

```

```{r subset-hint-1}
#dds_T04 <- dds[,SELECTION]
#design(dds_T04) <- NEW_DESIGN
```

```{r subset-hint-2}
#dds$time
#dds_T04 <- dds[,SELECTION]
#design(dds_T04) <- NEW_DESIGN
```

```{r subset-solution}
#dds_T04 <- dds[,dds$time=="T04"]
#design(dds_T04) <- ~ treatment
```

```{r dds_T04, include=FALSE, eval=TRUE}
#dds_T04 <- readRDS(file=here("tutorials/03_differential_gene_expression/www/dds_T04-post.rds"))
```

Here are a few more things, that need to be adjusted (or almost always, at present it would not be an issue). Briefly, the variables in the model are factors and by subsampling, we might remove all entries from a given level; _i.e._ in our case, the `time` factor now only contains T04 and no longer T03. However, `dds$time` as a factor will still list both. If that variable was still present in the model, containing a level not present any longer, `DESeq` would complain that the `matrix is not full-rank`. In that case, you would need to reset the factor levels like so:

```{r levels, eval=FALSE, echo=TRUE}
#dds_T04$time <- droplevels(dds_T04$time)
```

Now that we have our subset, use the following block to re-run `DESeq()` on it. 
```{r subset-de, exercise=TRUE, exercise.eval=FALSE, exercise.setup="dds_T04", exercise.lines=5, exercise.timelimit=600}

```

```{r subset-de-hint}
#DESeq()
#resultsNames()
#summary()
```

```{r subset-de-solution}
#dds_T04 <- DESeq(dds_T04)
#resultsNames(dds_T04)
#G03_vs_G02_at_T04_simple <- results(dds_T04)
#summary(G03_vs_G02_at_T04_simple,alpha=0.01)
```

```{r G03_vs_G02_at_T04_simple, include=FALSE, eval=TRUE}
#G03_vs_G02_at_T04_simple <- readRDS(file=here("tutorials/03_differential_gene_expression/www/G03_vs_G02_at_T04_simple.rds"))
```

```{r subset-de-quiz}
quiz(caption="How does this compare?",
     question("Did we obtain more or less DE genes?",
              answer("More",correct=TRUE),
              answer("Less")),
     question("Is that expected?",
              answer("Yes",correct=TRUE),
              answer("No"),
              try_again=TRUE,
              post_message="Typically, simpler model will identify more genes as DE than more complex ones. Here, obviously we will not be able to find genes which are primarily affected by `time` between the two treatments")
     )
```

Finally, we can visualise that overlap. Here again, just demonstrating the use of an `R` package, inspired by `tidyverse` to create a Venn Diagram (simply run it). 
```{r venn-setup}
#G03_vs_G02_at_T04 <- readRDS(file=here("tutorials/03_differential_gene_expression/www/G03_vs_G02_at_T04.rds"))
#G03_vs_G02_at_T04_simple <- readRDS(file=here("tutorials/03_differential_gene_expression/www/G03_vs_G02_at_T04_simple.rds"))
```

```{r venn, exercise=TRUE, exercise.eval=FALSE, exercise.lines=12}
#suppressPackageStartupMessages(library(ggvenn))

#row_sel <- !is.na(G03_vs_G02_at_T04$padj) & 
#  G03_vs_G02_at_T04$padj <= 0.01 & 
#  abs(G03_vs_G02_at_T04$log2FoldChange) >= 0.5

#row_sel_simple <- !is.na(G03_vs_G02_at_T04_simple$padj) & 
#  G03_vs_G02_at_T04_simple$padj <= 0.01 & 
#  abs(G03_vs_G02_at_T04_simple$log2FoldChange) >= 0.5

#ggvenn(list(simple=rownames(G03_vs_G02_at_T04_simple)[row_sel_simple],
#            complex=rownames(G03_vs_G02_at_T04)[row_sel]))

```

Note: Using a simple model is often a very good way to start analysing data. Then, as you learn the properties of your data, you can run iterations (remember R4DS chapter 2) and progressively build it into a more complex one.

-->

## Conclusion

This is it. We have been through a DE analysis! You now have seen all what matters and been exposed to all the theory, block of code, _etc._ so you can do it on your own. Do not hesitate to get in touch if you are stuck in future analysis.

Now that we have a set of candidate genes, it is time to look into what their function might be!

We will start by exporting the results for the simple and complex model, so we can do the downstream analysis tomorrow!

```{r export, exercise=TRUE, exercise.eval=FALSE, exercise.setup= "dds-post"}
resultsNames(dds)
#Select the condition you prefer instead of the one I wrote here
some_results <- results(dds,name="Condition_6h_5C_vs_24h_neg5C")

some_results %>% 
  as.data.frame() %>% 
  rownames_to_column("geneID") %>% 
  #Please do not change the name of the saved file, as future code will use it
  write_tsv(file=here("inst/tutorials/03_differential_gene_expression/some_results.tsv"))

```

## Session Info
It is good practice and highly recommended to always include the session info in your analyses. This way other can reproduce them with the exact same versions of the packages you used. Use the help to find out how to print the session info.

```{r session-info, exercise=TRUE, exercise.eval=TRUE}

```

```{r session-info-hint}
sessionInfo()
```

## Copyright
This material is provided under the following license:

`CC-BY-NC-SA 4.0:` _Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License_

by **BN Bioinformatics Handelsbolag**
